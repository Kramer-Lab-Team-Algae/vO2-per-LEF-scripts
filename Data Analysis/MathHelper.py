# imports
# scipy/anaconda imports
import pandas
from scipy import stats
import numpy
# python standard library imports
import math
import statistics
import copy
import collections
import time

nan = float("nan")


def fit_line(x_data, y_data):
	"""
performs a linear fit to the data and return the slope, y-intercept, R-squared 
value, P value, and standard error for the fit. Use as follows:

// x and y are lists of numbers with more than 75 elements
// fitting points 25 through 75 in from the data
start = 25
end = 75
slope, y_intercept, r_squared, p_value, std_err = MathHelper.fit_line(x[start:end], y[start,end])
print( str.format("Fitted formula: Y = {a}X + {b}", a=slope, b=y_intercept))
print( str.format("\tR-squared = {r2}", r2=r_squared))

	"""
	slope, y_intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)
	r_squared = r_value * r_value
	return slope, y_intercept, r_squared, p_value, std_err

def chi_squared_of_fit(y_data, fitted_y_data):
	"""
This function calculates and returnsthe Chi-squared value of a generated set 
of Y values (fitted_y_data) against the observed Y values (y_data).
	"""
	# note that in the typical definition of Chi-squared, it is assumed that 
	# nature is wrong and our formula is theoretically perfect, but here we 
	# are testing a model against emperical data, so the "expected" values 
	# are the data we measured and the "observed" values are the values 
	# generated by a fitting formula, and therefore we swap these variables 
	# in the stats.chisquare(...) invocation
	return stats.chisquare(fitted_y_data,y_data)


def r_squared(y_data,test_y_data):
	average = 0
	iii = 0
	size = len(y_data)
	for n in range(0,size):
		average += y_data[n]
		iii += 1
	average = average / iii
	sumResidual = 0
	sumTotal = 0
	for n in range(0,size):
		d = y_data[n]
		sim = test_y_data[n]
		sumResidual += (d - sim)*(d - sim)
		sumTotal += (d - average)*(d - average)
	return 1 - (sumResidual / sumTotal)


def _fit_err(x_data, y_data, formula_function, coefficient_vector):
	"""
quickly calculates a simple fitting error value (this is NOT standard error!)
	"""
	sum = 0;
	m = 1.0 / len(y_data)
	for n in range(0,len(x_data)):
		t = x_data[n]
		obs = y_data[n]
		sim = formula_function(*( t, coefficient_vector ) )
		er = sim - obs
		sum += er * er * m
	return sum

def fit_function_bruteforce(x_data, y_data, formula_function, coefficient_vector, max_iterations ):
	"""
This function uses a brute-force guess-and-check

x_data: the x values of the data set

y_data: the y values of the data set

formula_function: a function whose input parameters are (x, coefficient_vector)
                  and returns a single number by applying a formula to x with 
                  coefficients defined in coefficient_vector. For example, 
                  here's the fuction definition for an exponential decay fit 
                  where the coefficients are [A, tau, C] in the formula 
                  Y=A*e^(-x/tau)+C:

	def exponential_decay_function(x, cv_list):
		return cv_list[0] * math.exp( (-1 / cv_list[1]) x ) + cv_list[2]
	coefficients, precisions, iterations = fit_function_bruteforce(x, y, exponential_decay_function, [1,10,0], 1000000)
	print(str.format("fit: Y={A}*e^(-x/{tau})+{C}",A=coefficients[0], tau=coefficients[1], C=coefficients[2]))

coefficient_vector: list of numbers corresponding to coefficients in the 
                    formula which fit_function_bruteforce(...) will manipulate 
                    to try to fit he formula to the data. The starting values 
                    should be a best guess close to the actual value. If these 
                    values are too far off, the formula may get stick in a 
                    local maxima or edge-case

max_iterations: the maximum number of iterations through the fitting formula

returns coefficient_vector, precision, iteration_count: 
	returns the coefficient_vector after adjusting it to achieve the best 
	possible fit within the allowed number of iterations, the +/- precision 
	of the fit for each coefficient (also as a list), and the actual number 
	of iterations used to perform the fit
	"""
	iterations = 0
	# initialize deltas to the coefficients
	delta_vector = scalar_multiply(copy.deepcopy(coefficient_vector), 0.25)
	while(iterations < max_iterations):
		# scale-down the deltas by a factor of 2 each time
		delta_vector = scalar_multiply(delta_vector, 0.5)
		new_cv, jiggles = _improveFit(x_data, y_data, formula_function, coefficient_vector, delta_vector, max_iterations - iterations)
		coefficient_vector = new_cv
		iterations += jiggles
	# done
	return coefficient_vector, delta_vector, iterations

def _improveFit(x,y,formula,cvec,delta, maxIterations):
	"""
jiggles the coefficients to improve the formula fit a little bit

x: x data

y: y data

formula: the fitting formula (see description for fit_function_bruteforce(...) )

cvec: coefficient vector (see description for fit_function_bruteforce(...) )

delta: list of jiggle sizes corresponding to cvec

maxIterations: maximum number of jiggles allowed before returning
	"""
	# adjust the variables by the delta amount in decrease the error value
	iterations = 0
	while True: # python does not support do-while loops
		lastErr = _fit_err(x,y,formula,cvec)
		for i in range(len(cvec)):
			oldC = cvec[i]
			upC = cvec[i]+delta[i]
			downC = cvec[i]-delta[i]
			# current fit error
			currentErr = _fit_err(x,y,formula,cvec)
			# increase the coefficient a little and check again
			cvec[i] = upC
			errPlus = _fit_err(x,y,formula,cvec)
			# decrease the coefficient a little and check again
			cvec[i] = downC
			errMinus = _fit_err(x,y,formula,cvec)
			if(errPlus < currentErr and errPlus < errMinus):
				# increase the variable
				cvec[i] = upC;
			elif(errMinus < currentErr):
				# decrease the variable
				cvec[i] = downC
			else:
				# no change
				cvec[i] = oldC
		iterations += 1
		if(lastErr <= _fit_err(x,y,formula,cvec) or iterations >= maxIterations):
			break
	return cvec, iterations

def scalar_multiply(vector_list, scalar):
	"""
Multiplies a vector (represented as a list of numbers) by a scalar value and 
returns the new vector (original vector values are not changed)s
	"""
	v = copy.deepcopy(vector_list)
	for i in range(0, len(v)):
		v[i] = v[i] * scalar
	return v

def p_value(set1, set2):
	"""
returns the T-test P-value for two independent sets of data
	"""
	s, p = stats.ttest_ind(set1, set2)
	return p

def mean(data_set):
	try:
		return statistics.mean(data_set)
	except:
		return nan

def stdev(data_set):
	if(len(data_set) < 2):
		return nan
	else:
		try:
			return statistics.stdev(data_set)
		except:
			return nan